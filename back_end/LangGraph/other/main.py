import logging
import asyncio
from datetime import datetime

from DrissionPage._configs.chromium_options import ChromiumOptions
from DrissionPage._pages.chromium_page import ChromiumPage
from langchain_community.document_loaders import PyMuPDFLoader, TextLoader, UnstructuredWordDocumentLoader, \
    UnstructuredExcelLoader, UnstructuredPowerPointLoader

from fastapi import FastAPI, UploadFile, File
import json
import os
import re
from typing import List, Dict, Optional

from langchain_ollama import OllamaEmbeddings
from langchain_community.tools import TavilySearchResults
from langchain_chroma import Chroma
from langchain_core.tools import Tool
from langchain_openai import ChatOpenAI
from langchain_text_splitters import CharacterTextSplitter, RecursiveCharacterTextSplitter
from langgraph.checkpoint.memory import MemorySaver
from langgraph.constants import END, START
from langgraph.graph import StateGraph
from pydantic import BaseModel, Field
from fastapi.middleware.cors import CORSMiddleware  # æ·»åŠ è¿™è¡Œ

model = "qwq-32b-preview",
temperature = 0,
max_tokens = 300,
api_key = "sk-e5b047bd720744cf8fdb3902d9151bfc",
base_url = "https://dashscope.aliyuncs.com/compatible-mode/v1",


class AgentState(BaseModel):
    messages: List[Dict[str, str]] = []
    current_input: str = ""
    thought: str = ""
    selected_tool: Optional[str] = None
    tool_input: str = ""
    tool_output: str = ""
    final_answer: str = ""
    status: str = "STARTING"


os.environ["TAVILY_API_KEY"] = "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"
search_tool = TavilySearchResults(max_results=2, time_range="day", )  # æ—¶é—´ä¸å‡†ç¡®-æœ‰1ä¸ªæœˆçš„å»¶è¿Ÿ


# å®šä¹‰å¯ç”¨å·¥å…·
async def calculator_tool(a: int, b: int):
    return a * b


async def get_now_time():
    return datetime.now().strftime("%Y-%m-%d %H:%M:%S")


tools = [
    Tool(
        name="search_tool",
        description="ç”¨äºæ‰§è¡Œä¸Šç½‘æœç´¢",
        func=search_tool
    ),
    Tool(
        name="calculator_tool",
        description="ç”¨äºæ‰§è¡Œä¸¤ä¸ªæ•°ç›¸ä¹˜",
        func=calculator_tool
    ),
    Tool(
        name="get_now_time",
        description="ä¸æ—¶é—´ç›¸å…³çš„ï¼Œä¼˜å…ˆä½¿ç”¨è¿™ä¸ªå·¥å…·ï¼Œç”¨äºè·å–å½“å‰æ—¶é—´",
        func=get_now_time
    )

]


async def chatbot(state: AgentState) -> AgentState:
    """æ€è€ƒä¸‹ä¸€æ­¥è¡ŒåŠ¨"""
    prompt = f"""
    åŸºäºç”¨æˆ·è¾“å…¥å’Œå½“å‰å¯¹è¯å†å²ï¼Œæ€è€ƒä¸‹ä¸€æ­¥è¡ŒåŠ¨ã€‚
    ç”¨æˆ·è¾“å…¥: {state.current_input}
    å¯ç”¨å·¥å…·: {[t.name + ': ' + t.description for t in tools]}

    è¯·å†³å®š:
    1. æ˜¯å¦éœ€è¦ä½¿ç”¨å·¥å…·
    2. å¦‚æœéœ€è¦ï¼Œé€‰æ‹©å“ªä¸ªå·¥å…·
    3. ä½¿ç”¨ä»€ä¹ˆå‚æ•°è°ƒç”¨å·¥å…·
    ä¸éœ€è¦æ‰“å°å‡ºæ€è€ƒè¿‡ç¨‹ï¼Œæˆ‘åªéœ€è¦æœ€ç»ˆç»“æœ
    å¯¹æ€è€ƒçš„ç»“æœä»¥jsonæ ¼å¼è¿›è¡Œè¿”å›ï¼Œè¯·ä¸¥æ ¼æŒ‰ç…§æ­¤æç¤ºæ‰§è¡Œï¼Œæ¯æ®µä¸éœ€è¦ç©ºè¡Œ    
    ä¸¾ä¸€äº›æ­£ç¡®çš„ä¾‹å­ï¼š
    {{"thought": "ç”¨æˆ·ä¼¼ä¹åœ¨è¯¢é—®æˆ‘æ˜¯è°ï¼Œå¯èƒ½æ˜¯åœ¨ç¡®è®¤èº«ä»½æˆ–è€…æƒ³è¦äº†è§£å…³äºæˆ‘çš„ä¿¡æ¯ã€‚ç”±äºè¿™æ˜¯ä¸€ä¸ªå¯¹è¯çš„å¼€å§‹ï¼Œæˆ‘éœ€è¦ç»™å‡ºä¸€ä¸ªåˆé€‚çš„è‡ªæˆ‘ä»‹ç»ï¼Œå¹¶ä¸”å¯èƒ½éœ€è¦è¿›ä¸€æ­¥äº†è§£ç”¨æˆ·çš„éœ€æ±‚æˆ–å…´è¶£ã€‚åŒæ—¶ï¼Œç”¨æˆ·æåˆ°äº†ä»–å«Lannyï¼Œæˆ‘å¯èƒ½éœ€è¦è®°ä½è¿™ä¸€ç‚¹ï¼Œä»¥ä¾¿åœ¨æœªæ¥çš„å¯¹è¯ä¸­ä½¿ç”¨ã€‚å¦å¤–ï¼Œæä¾›äº†ä¸¤ä¸ªå·¥å…·ï¼šsearch_toolå’Œcalculator_toolã€‚ç›®å‰çœ‹æ¥ï¼Œè¿™äº›å·¥å…·å¯èƒ½ä¸ç›´æ¥é€‚ç”¨äºå½“å‰çš„å¯¹è¯æƒ…å¢ƒï¼Œå› ä¸ºç”¨æˆ·ä¼¼ä¹æ˜¯åœ¨è¿›è¡Œç¤¾äº¤æ€§çš„é—®å€™è€Œä¸æ˜¯å¯»æ±‚ç‰¹å®šçš„ä¿¡æ¯æˆ–è®¡ç®—ã€‚ç„¶è€Œï¼Œå¦‚æœç”¨æˆ·åç»­æå‡ºç›¸å…³éœ€æ±‚ï¼Œæˆ‘å¯ä»¥è€ƒè™‘ä½¿ç”¨è¿™äº›å·¥å…·æ¥è¾…åŠ©å›ç­”ã€‚", "need_tool": "False", "tool": "", "tool_input": ""}}
    {{"thought": "é¦–å…ˆï¼Œæˆ‘éœ€è¦ç†è§£ç”¨æˆ·çš„é—®é¢˜ã€‚ç”¨æˆ·æƒ³è¦çŸ¥é“å¹¿å·ä»Šå¤©çš„å¤©æ°”æƒ…å†µï¼Œè¿™åº”è¯¥æ˜¯è¦è·å–å¤©æ°”ä¿¡æ¯ã€‚æˆ‘æ¥æƒ³æƒ³ï¼Œè¦å¾—åˆ°å¤©æ°”ä¿¡æ¯ï¼Œé€šå¸¸æœ‰å‡ ç§æ–¹å¼ã€‚ä¸€æ˜¯ç›´æ¥çŸ¥é“ï¼Œä½†ä½œä¸ºä¸€ä¸ªAIï¼Œæˆ‘å¹¶ä¸å…·å¤‡å®æ—¶è·å–å¤©æ°”æ•°æ®çš„èƒ½åŠ›ï¼Œæ‰€ä»¥éœ€è¦é€šè¿‡å…¶ä»–æ–¹å¼æ¥è·å¾—è¿™ä¸ªä¿¡æ¯ã€‚äºŒæ˜¯ä½¿ç”¨æœç´¢å¼•æ“æœç´¢å¤©æ°”ä¿¡æ¯ï¼Œä¸‰æ˜¯å¯èƒ½æœ‰ä¸“é—¨çš„å¤©æ°”APIï¼Œä½†åœ¨è¿™ä¸ªåœºæ™¯ä¸­ï¼Œåªæœ‰search_toolå’Œcalculator_toolä¸¤ä¸ªå·¥å…·å¯ç”¨ã€‚calculator_toolæ˜¯ç”¨äºæ‰§è¡Œä¸¤ä¸ªæ•°ç›¸ä¹˜çš„ï¼Œè¿™å’Œè·å–å¤©æ°”ä¿¡æ¯æ²¡æœ‰ç›´æ¥å…³ç³»ï¼Œæ‰€ä»¥å¯ä»¥æ’é™¤ã€‚é‚£åªå‰©ä¸‹search_toolï¼Œä¹Ÿå°±æ˜¯ç”¨äºæ‰§è¡Œä¸Šç½‘æœç´¢ã€‚é‚£ä¹ˆï¼Œæˆ‘éœ€è¦è€ƒè™‘å¦‚ä½•åˆ©ç”¨search_toolæ¥è·å–å¹¿å·ä»Šå¤©çš„å¤©æ°”ä¿¡æ¯ã€‚å¯èƒ½çš„æ€è·¯æ˜¯ï¼Œé€šè¿‡search_toolæœç´¢"å¹¿å·ä»Šå¤©å¤©æ°”"ç›¸å…³çš„å…³é”®è¯ï¼Œç„¶åä»æœç´¢ç»“æœä¸­æå–å‡ºå¤©æ°”ä¿¡æ¯ã€‚", "need_tool": "False", "tool": "", "tool_input": ""}}
    {{"thought": "æˆ‘éœ€è¦ç»™å‡ºä¸€ä¸ªåˆé€‚çš„è‡ªæˆ‘ä»‹ç»ï¼Œå¹¶ä¸”å¯èƒ½éœ€è¦è¿›ä¸€æ­¥äº†è§£ç”¨æˆ·çš„éœ€æ±‚æˆ–å…´è¶£ã€‚åŒæ—¶ï¼Œç”¨æˆ·æåˆ°äº†ä»–å«Lannyï¼Œæˆ‘å¯èƒ½éœ€è¦è®°ä½è¿™ä¸€ç‚¹ï¼Œä»¥ä¾¿åœ¨æœªæ¥çš„å¯¹è¯ä¸­ä½¿ç”¨ã€‚å¦å¤–ï¼Œæä¾›äº†ä¸¤ä¸ªå·¥å…·ï¼šsearch_toolå’Œcalculator_toolã€‚ç›®å‰çœ‹æ¥ï¼Œè¿™äº›å·¥å…·å¯èƒ½ä¸ç›´æ¥é€‚ç”¨äºå½“å‰çš„å¯¹è¯æƒ…å¢ƒï¼Œå› ä¸ºç”¨æˆ·ä¼¼ä¹æ˜¯åœ¨è¿›è¡Œç¤¾äº¤æ€§çš„é—®å€™è€Œä¸æ˜¯å¯»æ±‚ç‰¹å®šçš„ä¿¡æ¯æˆ–è®¡ç®—ã€‚ç„¶è€Œï¼Œå¦‚æœç”¨æˆ·åç»­æå‡ºç›¸å…³éœ€æ±‚ï¼Œæˆ‘å¯ä»¥è€ƒè™‘ä½¿ç”¨è¿™äº›å·¥å…·æ¥è¾…åŠ©å›ç­”ã€‚", "need_tool": "Ture", "tool": "calculator_tool", "tool_input": ""}}
    {{"thought":"ç”¨æˆ·åœ¨è¯¢é—®å¹¿å·ä»Šå¤©çš„å¤©æ°”ï¼Œè¿™æ˜¾ç„¶æ˜¯ä¸€ä¸ªå¤©æ°”æŸ¥è¯¢çš„é—®é¢˜ã€‚ä½œä¸ºä¸€ä¸ªAIåŠ©æ‰‹ï¼Œæˆ‘éœ€è¦æä¾›å‡†ç¡®çš„å¤©æ°”ä¿¡æ¯æ¥æ»¡è¶³ç”¨æˆ·çš„éœ€æ±‚ã€‚é¦–å…ˆï¼Œæˆ‘éœ€è¦ç¡®è®¤ç”¨æˆ·æ‰€åœ¨çš„ä½ç½®æ˜¯å¦æ˜¯å¹¿å·ï¼Œå› ä¸ºå¤©æ°”æ˜¯ä¸åœ°ç†ä½ç½®å¯†åˆ‡ç›¸å…³çš„ã€‚ä¸è¿‡ï¼Œç”¨æˆ·æ˜ç¡®æŒ‡å‡ºäº†æ˜¯å¹¿å·çš„å¤©æ°”ï¼Œæ‰€ä»¥è¿™ä¸€ç‚¹å¯ä»¥ç¡®å®šã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘éœ€è¦æ‰¾åˆ°è·å–å¹¿å·å½“å‰å¤©æ°”ä¿¡æ¯çš„æ–¹æ³•ã€‚ç”±äºæˆ‘æ˜¯ä¸€ä¸ªAIæ¨¡å‹ï¼Œæ²¡æœ‰ç›´æ¥è®¿é—®å®æ—¶æ•°æ®çš„èƒ½åŠ›ï¼Œæ‰€ä»¥éœ€è¦å€ŸåŠ©å¤–éƒ¨å·¥å…·æˆ–APIæ¥è·å–è¿™äº›ä¿¡æ¯ã€‚åœ¨è¿™ä¸ªåœºæ™¯ä¸­ï¼Œæˆ‘æœ‰ä¸¤ä¸ªå¯ç”¨çš„å·¥å…·ï¼šsearch_toolå’Œcalculator_toolã€‚å¾ˆæ˜æ˜¾ï¼Œcalculator_toolæ˜¯ç”¨äºæ•°å­¦è®¡ç®—çš„ï¼Œä¸å¤©æ°”æŸ¥è¯¢æ— å…³ï¼Œæ‰€ä»¥å¯ä»¥æ’é™¤ã€‚å› æ­¤ï¼Œæˆ‘éœ€è¦ä½¿ç”¨search_toolæ¥è¿›è¡Œç½‘ç»œæœç´¢ï¼Œä»¥è·å–å¹¿å·ä»Šå¤©çš„å¤©æ°”ä¿¡æ¯ã€‚ä¸ºäº†æœ‰æ•ˆåœ°ä½¿ç”¨search_toolï¼Œæˆ‘éœ€è¦æ„é€ ä¸€ä¸ªåˆé€‚çš„æœç´¢æŸ¥è¯¢ï¼Œä»¥ä¾¿å¾—åˆ°å‡†ç¡®å’Œæœ‰ç”¨çš„ç»“æœã€‚å¯èƒ½çš„æœç´¢æŸ¥è¯¢å¯ä»¥æ˜¯"å¹¿å·ä»Šå¤©å¤©æ°”"æˆ–è€…"å¹¿å·å®æ—¶å¤©æ°”"ç­‰ã€‚æ­¤å¤–ï¼Œæˆ‘è¿˜éœ€è¦è€ƒè™‘å¦‚ä½•ä»æœç´¢ç»“æœä¸­æå–å‡ºç”¨æˆ·éœ€è¦çš„å¤©æ°”ä¿¡æ¯ï¼Œæ¯”å¦‚æ¸©åº¦ã€é™é›¨æ¦‚ç‡ã€é£é€Ÿç­‰ã€‚è¿™å¯èƒ½éœ€è¦å¯¹æœç´¢ç»“æœè¿›è¡Œè§£æå’Œç­›é€‰ï¼Œä»¥æä¾›ç»™ç”¨æˆ·ä¸€ä¸ªæ¸…æ™°çš„ç­”æ¡ˆã€‚æ€»ä¹‹ï¼Œæˆ‘çš„è®¡åˆ’æ˜¯ä½¿ç”¨search_toolè¿›è¡Œç½‘ç»œæœç´¢ï¼Œè·å–å¹¿å·ä»Šå¤©çš„å¤©æ°”ä¿¡æ¯ï¼Œå¹¶å°†ç›¸å…³ä¿¡æ¯æ•´ç†åå›å¤ç»™ç”¨æˆ·ã€‚","need_tool":"True","tool":"search_tool","tool_input":"å¹¿å·ä»Šå¤©å¤©æ°”"}}
    é”™è¯¯ä¾‹å­ï¼š
    åŸºäºç”¨æˆ·è¾“å…¥å’Œå½“å‰å¯¹è¯å†å²ï¼Œæ€è€ƒä¸‹ä¸€æ­¥è¡ŒåŠ¨ã€‚ç”¨æˆ·è¾“å…¥:ä½ çŸ¥é“æˆ‘æ˜¯è°ï¼Ÿå¯ç”¨å·¥å…·:['search_tool:ç”¨äºæ‰§è¡Œä¸Šç½‘æœç´¢','calculator_tool:ç”¨äºæ‰§è¡Œä¸¤ä¸ªæ•°ç›¸ä¹˜']è¯·å†³å®š:1.æ˜¯å¦éœ€è¦ä½¿ç”¨å·¥å…·2.å¦‚æœéœ€è¦ï¼Œé€‰æ‹©å“ªä¸ªå·¥å…·3.ä½¿ç”¨ä»€ä¹ˆå‚æ•°è°ƒç”¨å·¥å…·å¯¹æ€è€ƒçš„ç»“æœä»¥jsonæ ¼å¼è¿›è¡Œè¿”å›ï¼Œè¯·ä¸¥æ ¼æŒ‰ç…§æ­¤æç¤ºæ‰§è¡Œï¼Œæ¯æ®µä¸éœ€è¦ç©ºè¡Œä¸¾ä¸€äº›ä¾‹å­ï¼š{{"thought":"ç”¨æˆ·ä¼¼ä¹åœ¨è¯¢é—®æˆ‘æ˜¯è°ï¼Œå¯èƒ½æ˜¯åœ¨ç¡®è®¤èº«ä»½æˆ–è€…æƒ³è¦äº†è§£å…³äºæˆ‘çš„ä¿¡æ¯ã€‚ç”±äºè¿™æ˜¯ä¸€ä¸ªå¯¹è¯çš„å¼€å§‹ï¼Œæˆ‘éœ€è¦ç»™å‡ºä¸€ä¸ªåˆé€‚çš„è‡ªæˆ‘ä»‹ç»ï¼Œå¹¶ä¸”å¯èƒ½éœ€è¦è¿›ä¸€æ­¥äº†è§£ç”¨æˆ·çš„éœ€æ±‚æˆ–å…´è¶£ã€‚åŒæ—¶ï¼Œç”¨æˆ·æåˆ°äº†ä»–å«Lannyï¼Œæˆ‘å¯èƒ½éœ€è¦è®°ä½è¿™ä¸€ç‚¹ï¼Œä»¥ä¾¿åœ¨æœªæ¥çš„å¯¹è¯ä¸­ä½¿ç”¨ã€‚å¦å¤–ï¼Œæä¾›äº†ä¸¤ä¸ªå·¥å…·ï¼šsearch_toolå’Œcalculator_toolã€‚ç›®å‰çœ‹æ¥ï¼Œè¿™äº›å·¥å…·å¯èƒ½ä¸ç›´æ¥é€‚ç”¨äºå½“å‰çš„å¯¹è¯æƒ…å¢ƒï¼Œå› ä¸ºç”¨æˆ·ä¼¼ä¹æ˜¯åœ¨è¿›è¡Œç¤¾äº¤æ€§çš„é—®å€™è€Œä¸æ˜¯å¯»æ±‚ç‰¹å®šçš„ä¿¡æ¯æˆ–è®¡ç®—ã€‚ç„¶è€Œï¼Œå¦‚æœç”¨æˆ·åç»­æå‡ºç›¸å…³éœ€æ±‚ï¼Œæˆ‘å¯ä»¥è€ƒè™‘ä½¿ç”¨è¿™äº›å·¥å…·æ¥è¾…åŠ©å›ç­”ã€‚","need_tool":"False","tool":"","tool_input":""}}
    {{"thought":"é¦–å…ˆï¼Œæˆ‘éœ€è¦ç†è§£ç”¨æˆ·çš„é—®é¢˜ã€‚ç”¨æˆ·æƒ³è¦çŸ¥é“å¹¿å·ä»Šå¤©çš„å¤©æ°”æƒ…å†µï¼Œè¿™åº”è¯¥æ˜¯è¦è·å–å¤©æ°”ä¿¡æ¯ã€‚æˆ‘æ¥æƒ³æƒ³ï¼Œè¦å¾—åˆ°å¤©æ°”ä¿¡æ¯ï¼Œé€šå¸¸æœ‰å‡ ç§æ–¹å¼ã€‚ä¸€æ˜¯ç›´æ¥çŸ¥é“ï¼Œä½†ä½œä¸ºä¸€ä¸ªAIï¼Œæˆ‘å¹¶ä¸å…·å¤‡å®æ—¶è·å–å¤©æ°”æ•°æ®çš„èƒ½åŠ›ï¼Œæ‰€ä»¥éœ€è¦é€šè¿‡å…¶ä»–æ–¹å¼æ¥è·å¾—è¿™ä¸ªä¿¡æ¯ã€‚äºŒæ˜¯ä½¿ç”¨æœç´¢å¼•æ“æœç´¢å¤©æ°”ä¿¡æ¯ï¼Œä¸‰æ˜¯å¯èƒ½æœ‰ä¸“é—¨çš„å¤©æ°”APIï¼Œä½†åœ¨è¿™ä¸ªåœºæ™¯ä¸­ï¼Œåªæœ‰search_toolå’Œcalculator_toolä¸¤ä¸ªå·¥å…·å¯ç”¨ã€‚calculator_toolæ˜¯ç”¨äºæ‰§è¡Œä¸¤ä¸ªæ•°ç›¸ä¹˜çš„ï¼Œè¿™å’Œè·å–å¤©æ°”ä¿¡æ¯æ²¡æœ‰ç›´æ¥å…³ç³»ï¼Œæ‰€ä»¥å¯ä»¥æ’é™¤ã€‚é‚£åªå‰©ä¸‹search_toolï¼Œä¹Ÿå°±æ˜¯ç”¨äºæ‰§è¡Œä¸Šç½‘æœç´¢ã€‚é‚£ä¹ˆï¼Œæˆ‘éœ€è¦è€ƒè™‘å¦‚ä½•åˆ©ç”¨search_toolæ¥è·å–å¹¿å·ä»Šå¤©çš„å¤©æ°”ä¿¡æ¯ã€‚å¯èƒ½çš„æ€è·¯æ˜¯ï¼Œé€šè¿‡search_toolæœç´¢"å¹¿å·ä»Šå¤©å¤©æ°”"ç›¸å…³çš„å…³é”®è¯ï¼Œç„¶åä»æœç´¢ç»“æœä¸­æå–å‡ºå¤©æ°”ä¿¡æ¯ã€‚","need_tool":"False","tool":"","tool_input":""}}
    {{"thought":"æˆ‘éœ€è¦ç»™å‡ºä¸€ä¸ªåˆé€‚çš„è‡ªæˆ‘ä»‹ç»ï¼Œå¹¶ä¸”å¯èƒ½éœ€è¦è¿›ä¸€æ­¥äº†è§£ç”¨æˆ·çš„éœ€æ±‚æˆ–å…´è¶£ã€‚åŒæ—¶ï¼Œç”¨æˆ·æåˆ°äº†ä»–å«Lannyï¼Œæˆ‘å¯èƒ½éœ€è¦è®°ä½è¿™ä¸€ç‚¹ï¼Œä»¥ä¾¿åœ¨æœªæ¥çš„å¯¹è¯ä¸­ä½¿ç”¨ã€‚å¦å¤–ï¼Œæä¾›äº†ä¸¤ä¸ªå·¥å…·ï¼šsearch_toolå’Œcalculator_toolã€‚ç›®å‰çœ‹æ¥ï¼Œè¿™äº›å·¥å…·å¯èƒ½ä¸ç›´æ¥é€‚ç”¨äºå½“å‰çš„å¯¹è¯æƒ…å¢ƒï¼Œå› ä¸ºç”¨æˆ·ä¼¼ä¹æ˜¯åœ¨è¿›è¡Œç¤¾äº¤æ€§çš„é—®å€™è€Œä¸æ˜¯å¯»æ±‚ç‰¹å®šçš„ä¿¡æ¯æˆ–è®¡ç®—ã€‚ç„¶è€Œï¼Œå¦‚æœç”¨æˆ·åç»­æå‡ºç›¸å…³éœ€æ±‚ï¼Œæˆ‘å¯ä»¥è€ƒè™‘ä½¿ç”¨è¿™äº›å·¥å…·æ¥è¾…åŠ©å›ç­”ã€‚","need_tool":"Ture","tool":"calculator_tool","tool_input":""}}
    {{"thought":"ç”¨æˆ·åœ¨è¯¢é—®å¹¿å·ä»Šå¤©çš„å¤©æ°”ï¼Œè¿™æ˜¾ç„¶æ˜¯ä¸€ä¸ªå¤©æ°”æŸ¥è¯¢çš„é—®é¢˜ã€‚ä½œä¸ºä¸€ä¸ªAIåŠ©æ‰‹ï¼Œæˆ‘éœ€è¦æä¾›å‡†ç¡®çš„å¤©æ°”ä¿¡æ¯æ¥æ»¡è¶³ç”¨æˆ·çš„éœ€æ±‚ã€‚é¦–å…ˆï¼Œæˆ‘éœ€è¦ç¡®è®¤ç”¨æˆ·æ‰€åœ¨çš„ä½ç½®æ˜¯å¦æ˜¯å¹¿å·ï¼Œå› ä¸ºå¤©æ°”æ˜¯ä¸åœ°ç†ä½ç½®å¯†åˆ‡ç›¸å…³çš„ã€‚ä¸è¿‡ï¼Œç”¨æˆ·æ˜ç¡®æŒ‡å‡ºäº†æ˜¯å¹¿å·çš„å¤©æ°”ï¼Œæ‰€ä»¥è¿™ä¸€ç‚¹å¯ä»¥ç¡®å®šã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘éœ€è¦æ‰¾åˆ°è·å–å¹¿å·å½“å‰å¤©æ°”ä¿¡æ¯çš„æ–¹æ³•ã€‚ç”±äºæˆ‘æ˜¯ä¸€ä¸ªAIæ¨¡å‹ï¼Œæ²¡æœ‰ç›´æ¥è®¿é—®å®æ—¶æ•°æ®çš„èƒ½åŠ›ï¼Œæ‰€ä»¥éœ€è¦å€ŸåŠ©å¤–éƒ¨å·¥å…·æˆ–APIæ¥è·å–è¿™äº›ä¿¡æ¯ã€‚åœ¨è¿™ä¸ªåœºæ™¯ä¸­ï¼Œæˆ‘æœ‰ä¸¤ä¸ªå¯ç”¨çš„å·¥å…·ï¼šsearch_toolå’Œcalculator_toolã€‚å¾ˆæ˜æ˜¾ï¼Œcalculator_toolæ˜¯ç”¨äºæ•°å­¦è®¡ç®—çš„ï¼Œä¸å¤©æ°”æŸ¥è¯¢æ— å…³ï¼Œæ‰€ä»¥å¯ä»¥æ’é™¤ã€‚å› æ­¤ï¼Œæˆ‘éœ€è¦ä½¿ç”¨search_toolæ¥è¿›è¡Œç½‘ç»œæœç´¢ï¼Œä»¥è·å–å¹¿å·ä»Šå¤©çš„å¤©æ°”ä¿¡æ¯ã€‚ä¸ºäº†æœ‰æ•ˆåœ°ä½¿ç”¨search_toolï¼Œæˆ‘éœ€è¦æ„é€ ä¸€ä¸ªåˆé€‚çš„æœç´¢æŸ¥è¯¢ï¼Œä»¥ä¾¿å¾—åˆ°å‡†ç¡®å’Œæœ‰ç”¨çš„ç»“æœã€‚å¯èƒ½çš„æœç´¢æŸ¥è¯¢å¯ä»¥æ˜¯"å¹¿å·ä»Šå¤©å¤©æ°”"æˆ–è€…"å¹¿å·å®æ—¶å¤©æ°”"ç­‰ã€‚æ­¤å¤–ï¼Œæˆ‘è¿˜éœ€è¦è€ƒè™‘å¦‚ä½•ä»æœç´¢ç»“æœä¸­æå–å‡ºç”¨æˆ·éœ€è¦çš„å¤©æ°”ä¿¡æ¯ï¼Œæ¯”å¦‚æ¸©åº¦ã€é™é›¨æ¦‚ç‡ã€é£é€Ÿç­‰ã€‚è¿™å¯èƒ½éœ€è¦å¯¹æœç´¢ç»“æœè¿›è¡Œè§£æå’Œç­›é€‰ï¼Œä»¥æä¾›ç»™ç”¨æˆ·ä¸€ä¸ªæ¸…æ™°çš„ç­”æ¡ˆã€‚æ€»ä¹‹ï¼Œæˆ‘çš„è®¡åˆ’æ˜¯ä½¿ç”¨search_toolè¿›è¡Œç½‘ç»œæœç´¢ï¼Œè·å–å¹¿å·ä»Šå¤©çš„å¤©æ°”ä¿¡æ¯ï¼Œå¹¶å°†ç›¸å…³ä¿¡æ¯æ•´ç†åå›å¤ç»™ç”¨æˆ·ã€‚","need_tool":"True","tool":"search_tool","tool_input":"å¹¿å·ä»Šå¤©å¤©æ°”"}}

    ä¸¥æ ¼æŒ‰ç…§ä¾‹å­çš„æ ¼å¼
    ä»¥JSONæ ¼å¼è¿”å›,åªéœ€è¦è¿”å›å¦‚ä¸‹æ ¼å¼å†…å®¹: {{"thought": "æ€è€ƒè¿‡ç¨‹", "need_tool": "True/False", "tool": "å·¥å…·å", "tool_input": "å‚æ•°"}}

    """

    # å®šä¹‰llm
    llm = ChatOpenAI(
        # model="qwen-max",
        model="qwq-32b-preview",
        temperature=0,
        max_tokens=300,
        api_key="sk-e5b047bd720744cf8fdb3902d9151bfc",
        base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
        streaming=True,
        # model_kwargs={ "response_format": '' }
    )

    class ResponseFormatter(BaseModel):
        """Always use this tool to output your response to the user."""
        thought: str = Field(description="æ€è€ƒè¿‡ç¨‹")  # ,æ˜¯å­—å…¸æ ¼å¼ï¼ï¼ï¼
        need_tool: str = Field(description="æ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…·,True/False")
        tool: str = Field(description="è°ƒç”¨çš„å·¥å…·å")
        tool_input: str = Field(description="è°ƒç”¨å·¥å…·çš„å‚æ•°")

    # response = await llm.ainvoke(prompt)
    # å¯¹ç¬¬ä¸€æ¬¡è°ƒç”¨llmç”Ÿæˆçš„æ•°æ®è¿›è¡Œ è¾“å‡ºæ•´ç†
    llm_with_tool = llm.bind_tools(tools=[ResponseFormatter])
    response = await llm_with_tool.ainvoke(prompt)

    res = response.content.replace('\n', '').replace(' ', '').strip()
    json_pattern = r'\{.*?\}'
    try:
        # ä½¿ç”¨ re.findall æ‰¾åˆ°æ‰€æœ‰åŒ¹é…çš„ JSON å­—ç¬¦ä¸²
        res = re.search(json_pattern, res, re.DOTALL).group(0)

        print("bot: ", res, type(response.content), '\n------')
        # print('dict: ',eval(res))

        result = json.loads(res)
    except Exception as e:
        return AgentState(
            messages=state.messages,
            current_input=state.current_input,
            thought=state.thought,
            selected_tool=state.selected_tool,
            tool_input=state.tool_input,
            tool_output=state.tool_output,
            final_answer=state.final_answer,
            status="chatbot"
        )

    print('æ˜¯å¦éœ€è¦å·¥å…·', result["need_tool"])
    state = AgentState(
        messages=state.messages,
        current_input=state.current_input,
        thought=result["thought"],
        selected_tool=result.get("tool"),
        tool_input=result.get("tool_input"),
        tool_output=state.tool_output,
        final_answer=state.final_answer,
        status="GENERATE_RESPONSE" if result["need_tool"] == 'False' else "NEED_TOOL"
    )
    return state


async def execute_tool(state: AgentState) -> AgentState:
    """Execute the selected tool with the given input."""
    # tool æ˜¯ä»€ä¹ˆï¼Ÿ
    print(f"Tool Selected: {state.selected_tool}")
    print(f"Tool Input: {state.tool_input}")

    tool_to_use = None
    for tool in tools:
        if tool.name == state.selected_tool:
            tool_to_use = tool
            break

    if tool_to_use is None:
        state.tool_output = "Tool not found"
        state.status = "ERROR"
        return state

    try:
        print(tool_to_use, tool_to_use.name)

        # Check if the tool function has an ainvoke method
        if hasattr(tool_to_use.func, 'ainvoke'):
            result = await tool_to_use.func.ainvoke(state.tool_input)
        elif callable(tool_to_use.func):
            # If it's a regular async function, call it directly
            # Parse the tool input if it's a JSON string
            try:
                if state.tool_input and isinstance(state.tool_input, str):
                    # Try to parse as JSON
                    params = json.loads(state.tool_input)
                    if isinstance(params, dict):
                        result = await tool_to_use.func(**params)
                    else:
                        result = await tool_to_use.func(params)
                else:
                    # If not a string or empty, just call the function
                    result = await tool_to_use.func()
            except json.JSONDecodeError:
                # If not valid JSON, pass it as is
                result = await tool_to_use.func(state.tool_input)
        else:
            result = "Tool function is not callable"

        state.tool_output = str(result)
        state.status = "TOOL_EXECUTED"
        print(f"Tool Output: {state.tool_output}")
    except Exception as e:
        state.tool_output = f"Error executing tool: {str(e)}"
        state.status = "ERROR"
        print(f"Tool Error: {state.tool_output}")

    return state


async def generate_response(state: AgentState) -> AgentState:
    """ç”Ÿæˆæœ€ç»ˆå“åº”"""
    prompt = f"""
    åŸºäºä»¥ä¸‹ä¿¡æ¯ç”Ÿæˆå¯¹ç”¨æˆ·çš„å›å¤:
    ç”¨æˆ·è¾“å…¥: {state.current_input}
    
    å·¥å…·è¾“å‡º: {state.tool_output}

    è¯·æ ¹æ®è¿™äº›ä¿¡æ¯ï¼Œè¿›è¡Œæ±‡æ€»ï¼Œç”Ÿæˆä¸€ä¸ªç®€æ´æ¸…æ™°ã€æœ‰å¸®åŠ©çš„å›å¤ã€‚
    é‡ç‚¹å…³æ³¨å›å¤ï¼Œä¸è¦æœ‰å¤ªå¤šçš„æ€è€ƒè¿‡ç¨‹ï¼Œå›ç­”ç®€æ´æ˜äº†
    ä¸¾ä¾‹ï¼š
        ç›¸å¯¹è®ºæ˜¯ç”±é˜¿å°”ä¼¯ç‰¹Â·çˆ±å› æ–¯å¦å‘æ˜çš„ã€‚ä»–åœ¨1905å¹´æå‡ºäº†ç‹­ä¹‰ç›¸å¯¹è®ºï¼Œå¹¶åœ¨1915å¹´æå‡ºäº†å¹¿ä¹‰ç›¸å¯¹è®ºã€‚è¿™äº›ç†è®ºå½»åº•æ”¹å˜äº†æˆ‘ä»¬å¯¹æ—¶é—´ã€ç©ºé—´å’Œé‡åŠ›çš„ç†è§£ï¼Œå¹¶å¯¹ç°ä»£ç‰©ç†å­¦äº§ç”Ÿäº†æ·±è¿œçš„å½±å“ã€‚
    """

    # å®šä¹‰llm
    llm = ChatOpenAI(
        # model="qwen-max",
        model="qwq-plus",
        temperature=0.1,
        max_tokens=1000,
        api_key="sk-e5b047bd720744cf8fdb3902d9151bfc",
        base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
        streaming=True,
        # model_kwargs={ "response_format": '' }
    )
    response = await llm.ainvoke(prompt)
    print('æœ€ç»ˆç»“æœresï¼š ', response, type(response))
    return AgentState(
        messages=state.messages,
        current_input=state.current_input,
        thought=state.thought,
        selected_tool=state.selected_tool,
        tool_input=state.tool_input,
        tool_output=state.tool_output,
        final_answer=response.content,
        status="SUCCESS"
    )


async def error_handler(state: AgentState) -> AgentState:
    """é”™è¯¯å¤„ç†"""
    return AgentState(
        messages=state.messages,
        current_input=state.current_input,
        thought=state.thought,
        selected_tool=state.selected_tool,
        tool_input=state.tool_input,
        tool_output=state.tool_output,
        status="ERROR",
        final_answer="Sorry, I encountered an error."
    )


# åˆ›å»ºå›¾ç»“æ„
workflow = StateGraph(AgentState)

# æ·»åŠ èŠ‚ç‚¹
workflow.add_node("chatbot", chatbot)
workflow.add_node("execute_tool", execute_tool)
workflow.add_node("generate_response", generate_response)
workflow.add_node("error_handler", error_handler)


# å®šä¹‰è·¯ç”±å‡½æ•°
def route_next_step(state: AgentState) -> str:
    if state.status == "ERROR":
        return "error"
    elif state.status == "NEED_TOOL":
        return "execute_tool"
    elif state.status == "GENERATE_RESPONSE":
        return "generate_response"
    elif state.status == "SUCCESS":
        return "end"
    elif state.status == "chatbot":
        return "chatbot"

    return "chatbot"


workflow.add_edge(START, "chatbot")  # æ·»åŠ æ¡ä»¶è¾¹
workflow.add_conditional_edges(
    "chatbot",
    route_next_step,
    {
        "execute_tool": "execute_tool",
        "generate_response": "generate_response",
        "error": "error_handler",
        "chatbot": "chatbot",
        # "end": END
    }
)

workflow.add_conditional_edges(
    "execute_tool",
    route_next_step,
    {
        "generate_response": "generate_response",
        "error": "error_handler",
        # "end": END
        "chatbot": "chatbot",
    }
)

workflow.add_edge("generate_response", END)
workflow.add_edge("error_handler", END)
# å¢åŠ å†…å­˜åŠŸèƒ½
memory = MemorySaver()

# ç¼–è¯‘å›¾
# app = workflow.compile(checkpointer=memory)
graph = workflow.compile()
# ç”Ÿæˆå›¾
mermaid_code = graph.get_graph().draw_mermaid_png()
with open("chatbot-tool.jpg", "wb") as f:
    f.write(mermaid_code)


async def run_agent(state: AgentState):
    # ç°åœ¨è¿”å›çš„æ˜¯adddictç±»å‹
    final_state = await graph.ainvoke(state)
    # print(final_state, type(final_state))
    # print(final_state['current_input'], type(final_state['current_input']))
    # æ‰‹åŠ¨å°†æ¶ˆæ¯æ·»åŠ åˆ°ä¸Šä¸‹æ–‡
    state.messages.append({"role": "user", "content": final_state['current_input']})
    state.messages.append({"role": "ai", "content": final_state['final_answer']})
    print('\næ¶ˆæ¯åˆ—è¡¨ï¼š', state.messages, '\n')
    state.messages = state.messages[-5:]  # ä¿å­˜æœ€è¿‘5æ¡æ¶ˆæ¯çš„ä¸Šä¸‹æ–‡   å¦‚æœåç»­éœ€è¦æŒä¹…åŒ–ä¿å­˜æ¶ˆæ¯çš„è¯ï¼Œåˆ™æ¯ç”Ÿæˆä¸€æ¬¡ï¼Œå°†æ•°æ®æ·»åŠ åˆ°æ•°æ®åº“ä¸­
    state = AgentState(
        messages=state.messages,
        current_input=final_state['current_input'],
        thought=final_state['thought'],
        selected_tool=final_state['selected_tool'],
        tool_input=final_state['tool_input'],
        tool_output=final_state['tool_output'],
        final_answer=final_state['final_answer'],
        status=final_state['status'],
    )
    print('-----', state.final_answer)
    return state


# ä½¿ç”¨ç¤ºä¾‹
async def main(query: str):
    state = AgentState()
    print(f"\né—®é¢˜: {query}")
    state.current_input = query
    answer = await run_agent(state)
    print(f"å›ç­”: {answer.final_answer}")
    return answer.final_answer


app = FastAPI()
# æ·»åŠ CORSä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # å…è®¸æ‰€æœ‰æ¥æºï¼Œç”Ÿäº§ç¯å¢ƒåº”æŒ‡å®šå…·ä½“åŸŸå
    allow_credentials=True,
    allow_methods=["*"],  # å…è®¸æ‰€æœ‰æ–¹æ³•
    allow_headers=["*"],  # å…è®¸æ‰€æœ‰å¤´
)
# åœ¨FastAPIåº”ç”¨å¯åŠ¨å‰æ·»åŠ æ—¥å¿—é…ç½®
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)


@app.get("/")
async def root():
    return {"message": "Hello World, I'm a chatbotğŸ¤–"}


@app.get("/test")
async def root(question: str):
    return {"message": f"{question}\n hello,I don't knowâœˆï¸ğŸš„"}


@app.get("/test/{name}")
async def say_hello(name: str):
    return {"message": f"Hello {name}"}


@app.get("/chatbot")
async def say_hello(query: str = None):
    if query is None:
        return {"message": "Hello, World!"}
    logging.debug(f"Received name: {query}")
    res = await main(query)
    logging.debug(f"Received res: {res}")
    return {"message": f"Hello {res}"}

"""
ç”¨äºä¸Šä¼ æœ¬åœ°æ–‡ä»¶
"""
@app.post("/chatbot/upload/file")
async def upload_file(file: UploadFile = File(...)):
    logging.info(f"Received file: {file}")

    # 1ã€è·å–æ–‡ä»¶å
    filename = file.filename
    logging.info(f"filename: {filename}")

    # 2ã€è·å–æ–‡ä»¶ç±»å‹
    filetype = filename.split('.')[-1]
    logging.info(f"filetype: {filetype}")

    # 3ã€è·å–æ–‡ä»¶å†…å®¹
    content = await file.read()
    # ä¿å­˜æ–‡ä»¶
    with open(f'./files/{filename}', "wb") as f:
        f.write(content)
    logging.info(f"file saved: {filename}")
    file_path = f'./files/{filename}'
    # 4ã€åˆ¤æ–­æ–‡ä»¶ï¼Œå¹¶åŠ è½½
    if filetype == 'pdf':
        data = PyMuPDFLoader(file_path).load()  # æ¯é¡µè¿”å›ä¸€ä¸ªdocumentæ–‡æ¡£  æ˜¯ä¸ªåˆ—è¡¨ï¼Œéœ€è¦éå†è·å–

    elif filetype == 'txt':
        data = TextLoader(file_path).load()  # æ¯é¡µè¿”å›ä¸€ä¸ªdocumentæ–‡æ¡£  æ˜¯ä¸ªåˆ—è¡¨ï¼Œéœ€è¦éå†è·å–

    elif filetype in ['doc','docx']:
        data = UnstructuredWordDocumentLoader(file_path).load()  # æ¯é¡µè¿”å›ä¸€ä¸ªdocumentæ–‡æ¡£  æ˜¯ä¸ªåˆ—è¡¨ï¼Œéœ€è¦éå†è·å–
    elif filetype in ['xls','xlsx']:
        data = UnstructuredExcelLoader(file_path).load()  # æ¯é¡µè¿”å›ä¸€ä¸ªdocumentæ–‡æ¡£  æ˜¯ä¸ªåˆ—è¡¨ï¼Œéœ€è¦éå†è·å–
    elif filetype in ['ppt','pptx']:
        data = UnstructuredPowerPointLoader(file_path).load()  # æ¯é¡µè¿”å›ä¸€ä¸ªdocumentæ–‡æ¡£  æ˜¯ä¸ªåˆ—è¡¨ï¼Œéœ€è¦éå†è·å–
    else:
        try:
            data = TextLoader(file_path).load()  # æ¯é¡µè¿”å›ä¸€ä¸ªdocumentæ–‡æ¡£  æ˜¯ä¸ªåˆ—è¡¨ï¼Œéœ€è¦éå†è·å–
        except Exception as e:
            return {"message": f"File {filename} uploaded failed",
                    "filename": filename,
                    # "content":content,
                    }
    # 5ã€åˆ›å»ºä¸€ä¸ªæ–‡æœ¬åˆ†å‰²å™¨ï¼Œchunksä»£è¡¨åˆ†æˆå¤šå°‘å—  chunk_overlap ç¡®ä¿ç›¸é‚»ç‰‡æ®µä¹‹é—´æœ‰ä¸€å®šçš„é‡å éƒ¨åˆ†
    text_splitter = CharacterTextSplitter(chunk_size=2000, chunk_overlap=200)
    # 6ã€ä½¿ç”¨æ–‡æœ¬åˆ†å‰²å™¨ï¼Œå°†åŸå§‹æ–‡æ¡£åˆ†å‰²æˆå¤šä¸ªç‰‡æ®µ   documentsæ˜¯ä¸€ä¸ªåˆ—è¡¨
    documents = text_splitter.split_documents(data)
    logging.info(f"documents: {documents}")
    # # 7ã€åˆå§‹åŒ–åµŒå…¥æ¨¡å‹
    # embeddings = OllamaEmbeddings(model="llama2")
    # # 8ã€åˆå§‹åŒ–å‘é‡æ•°æ®åº“
    # persist_directory = './vector/chroma1'  # æŒä¹…åŒ–æ•°æ®  å­˜æ”¾å¤„
    # vector_db = Chroma(persist_directory=persist_directory, embedding_function=embeddings, collection_name="test1")
    # # 9ã€å°†æ–‡ä»¶æ·»åŠ åˆ°å‘é‡æ•°æ®åº“ä¸­
    # vector_db.add_documents(documents)
    # è¿”å›ç»“æœ
    return {"message": f"File {filename} uploaded successfully",
            "filename": filename,
            # "content":content,
            }




@app.post("/chatbot/upload/text")
async def upload_text(text: str):
    logging.info(f"Received file: {text}")



    # 5ã€åˆ›å»ºä¸€ä¸ªæ–‡æœ¬åˆ†å‰²å™¨ï¼Œchunksä»£è¡¨åˆ†æˆå¤šå°‘å—  chunk_overlap ç¡®ä¿ç›¸é‚»ç‰‡æ®µä¹‹é—´æœ‰ä¸€å®šçš„é‡å éƒ¨åˆ†
    text_splitter = CharacterTextSplitter(chunk_size=2000, chunk_overlap=200)

    # 6ã€ä½¿ç”¨æ–‡æœ¬åˆ†å‰²å™¨ï¼Œå°†åŸå§‹æ–‡æ¡£åˆ†å‰²æˆå¤šä¸ªç‰‡æ®µ   documentsæ˜¯ä¸€ä¸ªåˆ—è¡¨
    documents = text_splitter.split_text(text)
    logging.info(f"documents: {documents}")

    # 7ã€åˆå§‹åŒ–åµŒå…¥æ¨¡å‹
    embeddings = OllamaEmbeddings(model="llama2")
    # 8ã€åˆå§‹åŒ–å‘é‡æ•°æ®åº“
    persist_directory = './vector/chroma1'  # æŒä¹…åŒ–æ•°æ®  å­˜æ”¾å¤„
    vector_db = Chroma(persist_directory=persist_directory, embedding_function=embeddings, collection_name="test1")
    # 9ã€å°†æ–‡ä»¶æ·»åŠ åˆ°å‘é‡æ•°æ®åº“ä¸­
    vector_db.add_texts(documents)

    # è¿”å›ç»“æœ
    return {"message": f" text uploaded successfully",
            # "content":content,
            }


@app.post("/chatbot/upload/website")
async def upload_file(url:str):
    logging.info(f"Received url: {url}")

    co = ChromiumOptions()
    co.incognito()  # åŒ¿åæ¨¡å¼
    co.headless()  # æ— å¤´æ¨¡å¼
    co.set_argument('--no-sandbox')  # æ— æ²™ç›’æ¨¡å¼
    tab = ChromiumPage(co)
    tab.get(url)
    res = tab.html




    # åˆ›å»ºä¸€ä¸ªæ–‡æœ¬åˆ†å‰²å™¨ï¼Œchunksä»£è¡¨åˆ†æˆå¤šå°‘å—  chunk_overlap ç¡®ä¿ç›¸é‚»ç‰‡æ®µä¹‹é—´æœ‰ä¸€å®šçš„é‡å éƒ¨åˆ†
    text_splitter = CharacterTextSplitter(chunk_size=2000, chunk_overlap=200)

    # 6ã€ä½¿ç”¨æ–‡æœ¬åˆ†å‰²å™¨ï¼Œå°†åŸå§‹æ–‡æ¡£åˆ†å‰²æˆå¤šä¸ªç‰‡æ®µ   documentsæ˜¯ä¸€ä¸ªåˆ—è¡¨
    documents = text_splitter.split_text(res)
    logging.info(f"documents: {documents}")

    # 7ã€åˆå§‹åŒ–åµŒå…¥æ¨¡å‹
    embeddings = OllamaEmbeddings(model="llama2")
    # 8ã€åˆå§‹åŒ–å‘é‡æ•°æ®åº“
    persist_directory = './vector/chroma1'  # æŒä¹…åŒ–æ•°æ®  å­˜æ”¾å¤„
    vector_db = Chroma(persist_directory=persist_directory, embedding_function=embeddings, collection_name="test1")
    # 9ã€å°†æ–‡ä»¶æ·»åŠ åˆ°å‘é‡æ•°æ®åº“ä¸­
    vector_db.add_texts(documents)

    # è¿”å›ç»“æœ
    return {"message": f"URL uploaded successfully",
            # "content":content,
            }
